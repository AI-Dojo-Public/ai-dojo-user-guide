# Deployment Pipeline
This document describes how automatic deployment via Gitlab Pipeline works, the technologies used, and how it is configured.

## Technologies
1. **Gitlab CI Pipeline** - automation in Gitlab
2. **Terraform** - deployment to cloud environment
3. **OpenStack** - cloud environment
4. **Ansible** - provisioning, AI-Dojo deployment, more about Ansible can be found [here](../README.md#automatic-deployment-using-ansible)

## Gitlab Pipeline
It creates compute instance in Openstack using Terraform, and it runs ai-dojo demo via Ansible provisioning. For more info about how to connect to the VM created by this pipeline, see the [relevant](#how-to-connect-to-the-vm-via-ssh) section below.
### Stages
#### 1. build
It has only one job: `terraform_plan`. It runs Gitlab's official Terraform image, where it generates SSH keys and executes the `terraform plan` command. Both keys and terraform files generated by the plan are passed as artifacts to the next job.

#### 2. deploy
The deploy stage has two jobs. First, `terraform_deployment` is based on the same image as `terraform_plan`, and it uses the plan's artifacts to deploy a compute instance to the OpenStack environment. This job also generates artifacts which can be downloaded through the Gitlab UI.

**Note for developers:** Artifacts contain SSH keys and commands for managing and testing the VM. SSH keys are located in `/demo-2023/deployment/ssh-keys`.

`ansible_provisioning` is the second job in this stage. It deploys the AI-Dojo to the compute instance in the OpenStack.

#### 3. cleanup
The cleanup stage has only one job: `terraform_destroy`. This job is manual, and it removes the compute instance from OpenStack. It uses again the same terraform image.

### Files and variables
#### Secure files
The pipeline uses [Secure files](https://gitlab.ics.muni.cz/help/ci/secure_files/index) where the `clouds.yaml` file is stored. This file is used to operate OpenStack, like deploy or destroy instances, etc.

#### Variables
Variables are listed and described in [`variables.tf`](./variables.tf). All variables except public and private keys (they are generated during the pipeline) must be defined for the pipeline to run correctly.

Variable name must be in the format `TF_VAR_*`, where * is a variable name from [`variables.tf`](./variables.tf).

### How to connect to the VM via SSH?
The simplest way is to use a generated command in the artifacts.
1. Download artifacts - from [Gitlab Environments](https://gitlab.ics.muni.cz/ai-dojo/ai-dojo/-/environments) by clicking the *Open* button next to the *MUNI_Openstack* environment or directly from the *terraform_deployment* job in the correct pipeline.
2. Run `ssh_command.sh`. From artifacts folder:
    ```bash
    chmod +x ssh_command.sh
    chmod 600 ./demo-2023/deployment/ssh-keys/ai-dojo-key
    ./ssh_command.sh ./demo-2023/deployment/ssh-keys/ai-dojo-key
    ```
3. SSH connection should be established.

The SSH command looks like this:
```bash
ssh -i ai-dojo-key -o IdentitiesOnly=yes ubuntu@<IP>
```
Where `ai-dojo-key` is from `artifacts/demo-2023/deployment/ssh-keys/ai-dojo-key` and `<IP>` is a public IP address assigned by OpenStack. IP is filled in the `ssh_command.sh` and is also in the output of *terraform_deployment* job.

## Gitlab Environments
The pipeline uses the [Gitlab Environments](https://docs.gitlab.com/ee/ci/environments/) feature for deployment. Environments are available in Gitlab under the Operate tab ([here](https://gitlab.ics.muni.cz/ai-dojo/ai-dojo/-/environments)). The environment shows which pipeline lastly deploys to OpenStack. Manual jobs like `terraform_destroy` can be quickly executed from the environment by clicking the play button. Moreover, the Open button is set to download the artifacts generated by the `terraform_deployment` job.

## Gitlab Terraform States
Terraform state is saved to Gitlab, and the pipeline can change it. The state shows which pipeline changed it last. States are in Operate tab > [Terraform states](https://gitlab.ics.muni.cz/ai-dojo/ai-dojo/-/terraform). Official documentation is available [here](https://docs.gitlab.com/ee/user/infrastructure/iac/terraform_state.html).

### Locking
Terraform state has a lock feature preventing more pipelines from changing it simultaneously. The first pipeline locks the state, and the others fail. This behaviour can cause an issue when the first pipeline fails. The pipeline may not unlock the state, so it remains locked even if no pipeline is working with it. Each new pipeline will then fail because of the locked state.

**Solution to lock issue:**
1. Check that no pipeline is running.
2. Go to Operate > [Terraform states](https://gitlab.ics.muni.cz/ai-dojo/ai-dojo/-/terraform).
3. Click on the state actions menu and select `unlock`.
4. Run the pipeline.
